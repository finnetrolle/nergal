# Telegram Bot Configuration
# Get your token from @BotFather on Telegram
TELEGRAM_BOT_TOKEN=your_bot_token_here

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Response Style Configuration
# Supported styles: default, silvio_dante
# - default: Neutral, helpful assistant
# - silvio_dante: Responses in the style of Silvio Dante from The Sopranos (Goblin translation)
STYLE=default

# LLM Provider Configuration
# Supported providers: zai, openai, anthropic, minimax
LLM_PROVIDER=zai
LLM_API_KEY=your_llm_api_key_here
# Model name (use UPPERCASE for Z.ai Coding Plan: GLM-4-flash, GLM-4.7, GLM-5)
LLM_MODEL=GLM-4-flash
# Optional: Custom API endpoint (leave empty for default)
# LLM_BASE_URL=
LLM_TEMPERATURE=0.7
# Optional: Maximum tokens to generate (leave empty for no limit)
# LLM_MAX_TOKENS=
# Request timeout in seconds (increase for complex queries with web search)
LLM_TIMEOUT=120.0

# Web Search Configuration
# Enable web search to allow the bot to search the internet
WEB_SEARCH_ENABLED=false
# API key for web search (defaults to LLM_API_KEY if not set)
# WEB_SEARCH_API_KEY=
# MCP endpoint URL for web search
WEB_SEARCH_MCP_URL=https://api.z.ai/api/mcp/web_search_prime/mcp
# Maximum number of search results to return (1-50)
WEB_SEARCH_MAX_RESULTS=5
# Request timeout for web search in seconds
WEB_SEARCH_TIMEOUT=30.0

# Speech-to-Text (Voice Message) Configuration
# Enable voice message processing with local Whisper
STT_ENABLED=true
# STT provider: local (faster-whisper) or openai (requires API key)
STT_PROVIDER=local
# Whisper model size: tiny, base, small, medium, large-v3
# - tiny: fastest, lowest quality (~1GB RAM)
# - base: good balance of speed and quality (~1GB RAM) [recommended for CPU]
# - small: better quality, slower (~2GB RAM)
# - medium: high quality, much slower (~5GB RAM)
# - large-v3: best quality, slowest (~10GB RAM)
STT_MODEL=base
# Language for transcription (ISO 639-1 code)
STT_LANGUAGE=ru
# Maximum voice message duration in seconds (60 = 1 minute)
STT_MAX_DURATION_SECONDS=60
# Device for Whisper: cpu or cuda (if GPU available)
STT_DEVICE=cpu
# Compute type: int8 (for CPU), float16 (for GPU), float32
STT_COMPUTE_TYPE=int8

# Database Configuration (PostgreSQL)
# Database host (use "postgres" for docker-compose, "localhost" for local dev)
DB_HOST=localhost
# Database port
DB_PORT=5432
# Database user
DB_USER=nergal
# Database password (change in production!)
DB_PASSWORD=nergal_secret
# Database name
DB_NAME=nergal
# Connection pool settings
DB_MIN_POOL_SIZE=5
DB_MAX_POOL_SIZE=20
# Connection timeout in seconds
DB_CONNECTION_TIMEOUT=30.0

# Memory System Configuration
# Maximum messages in short-term memory (conversation history)
MEMORY_SHORT_TERM_MAX_MESSAGES=50
# Session timeout in seconds (1 hour = 3600)
MEMORY_SHORT_TERM_SESSION_TIMEOUT=3600
# Enable long-term memory (user profiles)
MEMORY_LONG_TERM_ENABLED=true
# Enable automatic extraction of facts from messages
MEMORY_LONG_TERM_EXTRACTION_ENABLED=true
# Minimum confidence to store extracted fact (0.0-1.0)
MEMORY_LONG_TERM_CONFIDENCE_THRESHOLD=0.7
# Days to keep old messages before cleanup
MEMORY_CLEANUP_DAYS=30

# Monitoring Configuration
# Enable Prometheus metrics and structured logging
MONITORING_ENABLED=true
# Port for Prometheus metrics endpoint
MONITORING_METRICS_PORT=8000
# Use JSON format for logs (recommended for production/Loki)
MONITORING_JSON_LOGS=true
# Log level for monitoring (DEBUG, INFO, WARNING, ERROR)
MONITORING_LOG_LEVEL=INFO

# Grafana Configuration (for docker-compose)
GRAFANA_PASSWORD=admin
GRAFANA_URL=http://localhost:3000
